{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning - Neutrality Classifier\n",
    "   \n",
    "In this notebook, the manual content analysis data is used to train and evaluate a classifier that assesses the neutrality of an article.   \n",
    "The process includes feature selection, and the evaluation and comparison of different types of classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from pprint import pprint\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the manually coded data\n",
    "df = read_excel(\"mca_cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into test and training set\n",
    "I reran the following models with both the original and the cleaned text. I indicated which one led to better results for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    283\n",
       "0    204\n",
       "Name: NEU, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NEU\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and testing dataset \n",
    "x_train, x_test, y_train, y_test = train_test_split(df[\"clean text\"], df.NEU, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "   \n",
    "Four different types of text representations for the classifier training were used, namely count vectors, TF-IDF vectors with unigrams, and TF-IDF vectors with bigrams and TF-IDF vectors with both uni- and bigrams. All classifiers were trained and tested on all features.   \n",
    "First, the labels, which remain in a binary format, are renamed. After that, the different vector types are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = y_train\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 200)\n",
      "(98, 200)\n"
     ]
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer=\"word\", \n",
    "                             token_pattern=r\"\\w{1,10}\", \n",
    "                             min_df = 10, \n",
    "                             max_df = 1., \n",
    "                             max_features=200)\n",
    "\n",
    "#features for training\n",
    "features_train_count = count_vect.fit_transform(x_train).toarray()\n",
    "\n",
    "#features for testing\n",
    "features_test_count = count_vect.fit_transform(x_test).toarray()\n",
    "\n",
    "#inspect the shape\n",
    "print(features_train_count.shape)\n",
    "print(features_test_count.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectors\n",
    "In the following, Term Frequency-Inverse Document Frequency is applied in order to represent the text data as a vector that can be used as numerical input for a SML algorithm. \n",
    "Three different vectors are created:\n",
    "    - A vector with unigrams only\n",
    "    - A vector with bigrams only\n",
    "    - A vector with unigrams & bigrams\n",
    "    \n",
    "In addition to that, several parameters were specified:\n",
    "    - Terms that appear in less than 10 documents are ignored -> min_df\n",
    "    - All other terms are included -> max_df\n",
    "    - In total, up to 200 features can be extracted per text -> max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 200)\n",
      "(98, 200)\n"
     ]
    }
   ],
   "source": [
    "# unigrams\n",
    "tfidf_vect_ug = TfidfVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}',\n",
    "                             ngram_range = (1,1),\n",
    "                             min_df = 10, \n",
    "                             max_df = 1., \n",
    "                             max_features=200)\n",
    "\n",
    "# bigrams\n",
    "tfidf_vect_bg = TfidfVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}',\n",
    "                             ngram_range = (2,2),\n",
    "                             min_df = 10, \n",
    "                             max_df = 1., \n",
    "                             max_features= 6)  #because for at least one article there are only 6 features which leads to an error\n",
    "\n",
    "# unigrams and bigrams\n",
    "tfidf_vect_ubg = TfidfVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}',\n",
    "                             ngram_range = (1,2),\n",
    "                             min_df = 10, \n",
    "                             max_df = 1., \n",
    "                             max_features=200)\n",
    "\n",
    "\n",
    "#features for testing\n",
    "features_train_tfidf_ug = tfidf_vect_ug.fit_transform(x_train).toarray()\n",
    "features_train_tfidf_bg = tfidf_vect_bg.fit_transform(x_train).toarray()\n",
    "features_train_tfidf_ubg = tfidf_vect_ubg.fit_transform(x_train).toarray()\n",
    "\n",
    "#features (=y_train)\n",
    "features_test_tfidf_ug = tfidf_vect_ug.fit_transform(x_test).toarray()\n",
    "features_test_tfidf_bg = tfidf_vect_bg.fit_transform(x_test).toarray()\n",
    "features_test_tfidf_ubg = tfidf_vect_ubg.fit_transform(x_test).toarray()\n",
    "\n",
    "#Explore the shape of the features\n",
    "print(features_train_tfidf_ubg.shape)\n",
    "print(features_test_tfidf_ubg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training & evaluation\n",
    "In the following, different classifiers are trained and evaluated through their precision, recall and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, features_train, labels_train, features_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(features_train, labels_train)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(features_test)\n",
    "    #calculate the accuracy of the predictions\n",
    "    accuracy = classification_report(labels_test, predictions)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier\n",
    "First, the classifiers for different vectors are trained and evaluated on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.71      0.60        42\n",
      "           1       0.70      0.50      0.58        56\n",
      "\n",
      "    accuracy                           0.59        98\n",
      "   macro avg       0.61      0.61      0.59        98\n",
      "weighted avg       0.62      0.59      0.59        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.52      0.49        42\n",
      "           1       0.61      0.55      0.58        56\n",
      "\n",
      "    accuracy                           0.54        98\n",
      "   macro avg       0.54      0.54      0.54        98\n",
      "weighted avg       0.55      0.54      0.54        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.48      0.51        42\n",
      "           1       0.65      0.71      0.68        56\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.60      0.60      0.60        98\n",
      "weighted avg       0.61      0.61      0.61        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47        42\n",
      "           1       0.57      0.48      0.52        56\n",
      "\n",
      "    accuracy                           0.50        98\n",
      "   macro avg       0.50      0.50      0.50        98\n",
      "weighted avg       0.51      0.50      0.50        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining the classifier\n",
    "sgdc = SGDClassifier(loss=\"hinge\", max_iter=200, random_state=8) \n",
    "#training and evaluating the classifier\n",
    "train_model(sgdc, features_train_count, labels_train, features_test_count)\n",
    "train_model(sgdc, features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(sgdc, features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(sgdc, features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "Second, the results are cross-validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69 (+/- 0.08)\n",
      "Accuracy: 0.70 (+/- 0.15)\n",
      "Accuracy: 0.50 (+/- 0.55)\n",
      "Accuracy: 0.71 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "def cross_validate(classifier, features_train, labels_train, cv):\n",
    "    scores = cross_val_score(classifier, features_train, labels_train, cv=cv, scoring =\"f1\")\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "cross_validate(sgdc, features_train_count, labels_train, 10)\n",
    "cross_validate(sgdc, features_train_tfidf_ug, labels_train, 10)\n",
    "cross_validate(sgdc, features_train_tfidf_bg, labels_train, 10)\n",
    "cross_validate(sgdc, features_train_tfidf_ubg, labels_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "Third, a grid search is performed in order to establish the best model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator__alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', max_iter=200)\n",
    "calibrated_clf = CalibratedClassifierCV(base_estimator=clf, method='sigmoid', cv=10)\n",
    "\n",
    "grid_params = {'base_estimator__alpha': [0.0001, 0.001, 0.01, 0.1]}  \n",
    "grid_search = GridSearchCV(estimator=calibrated_clf, param_grid=grid_params, cv=10)\n",
    "grid_search.fit(features_train_count, labels_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.64      0.57        42\n",
      "           1       0.67      0.55      0.61        56\n",
      "\n",
      "    accuracy                           0.59        98\n",
      "   macro avg       0.60      0.60      0.59        98\n",
      "weighted avg       0.61      0.59      0.59        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgdc_final = SGDClassifier(loss=\"hinge\", alpha = .01, max_iter=200) \n",
    "#training and evaluating the classifier\n",
    "train_model(sgdc_final, features_train_count, labels_train, features_test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best classification results for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss=\"hinge\", alpha = .01, max_iter=200) \n",
    "clf.fit(features_train_count, labels_train,)\n",
    "sgdc_final = clf.predict(features_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "First, the classifiers for different vectors are trained and evaluated on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.71      0.62        42\n",
      "           1       0.72      0.55      0.63        56\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.63      0.63      0.62        98\n",
      "weighted avg       0.65      0.62      0.62        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.48      0.47        42\n",
      "           1       0.59      0.57      0.58        56\n",
      "\n",
      "    accuracy                           0.53        98\n",
      "   macro avg       0.52      0.52      0.52        98\n",
      "weighted avg       0.53      0.53      0.53        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.48        42\n",
      "           1       0.64      0.79      0.70        56\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.61      0.60      0.59        98\n",
      "weighted avg       0.62      0.62      0.61        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47        42\n",
      "           1       0.57      0.48      0.52        56\n",
      "\n",
      "    accuracy                           0.50        98\n",
      "   macro avg       0.50      0.50      0.50        98\n",
      "weighted avg       0.51      0.50      0.50        98\n",
      "\n",
      "\n",
      "\n",
      "Multinomial NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.45      0.42        42\n",
      "           1       0.54      0.48      0.51        56\n",
      "\n",
      "    accuracy                           0.47        98\n",
      "   macro avg       0.47      0.47      0.47        98\n",
      "weighted avg       0.48      0.47      0.47        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.21      0.33        42\n",
      "           1       0.61      0.93      0.74        56\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.65      0.57      0.53        98\n",
      "weighted avg       0.65      0.62      0.56        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.19      0.31        42\n",
      "           1       0.61      0.96      0.75        56\n",
      "\n",
      "    accuracy                           0.63        98\n",
      "   macro avg       0.71      0.58      0.53        98\n",
      "weighted avg       0.69      0.63      0.56        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.24      0.32        42\n",
      "           1       0.59      0.82      0.69        56\n",
      "\n",
      "    accuracy                           0.57        98\n",
      "   macro avg       0.54      0.53      0.50        98\n",
      "weighted avg       0.55      0.57      0.53        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "print(\"Gaussian NB\")\n",
    "train_model(GaussianNB(), features_train_count, labels_train, features_test_count)\n",
    "train_model(GaussianNB(), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(GaussianNB(), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(GaussianNB(), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Multinomial NB\")\n",
    "train_model(MultinomialNB(), features_train_count, labels_train, features_test_count)\n",
    "train_model(MultinomialNB(), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(MultinomialNB(), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(MultinomialNB(), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "Second, the results are cross-validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB; order: count, tfidf_ug, tfidf_bg, tfidf_ubg\n",
      "Accuracy: 0.71 (+/- 0.07)\n",
      "Accuracy: 0.71 (+/- 0.11)\n",
      "Accuracy: 0.62 (+/- 0.18)\n",
      "Accuracy: 0.70 (+/- 0.11)\n",
      "Multinomial NB; order: count, tfidf_ug, tfidf_bg, tfidf_ubg\n",
      "Accuracy: 0.75 (+/- 0.09)\n",
      "Accuracy: 0.77 (+/- 0.06)\n",
      "Accuracy: 0.72 (+/- 0.05)\n",
      "Accuracy: 0.77 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print(\"Gaussian NB; order: count, tfidf_ug, tfidf_bg, tfidf_ubg\")\n",
    "cross_validate(GaussianNB(), features_train_count, labels_train, 10)\n",
    "cross_validate(GaussianNB(), features_train_tfidf_ug, labels_train, 10)\n",
    "cross_validate(GaussianNB(), features_train_tfidf_bg, labels_train, 10)\n",
    "cross_validate(GaussianNB(), features_train_tfidf_ubg, labels_train, 10)\n",
    "print(\"Multinomial NB; order: count, tfidf_ug, tfidf_bg, tfidf_ubg\")\n",
    "cross_validate(MultinomialNB(), features_train_count, labels_train, 10)\n",
    "cross_validate(MultinomialNB(), features_train_tfidf_ug, labels_train, 10)\n",
    "cross_validate(MultinomialNB(), features_train_tfidf_bg, labels_train, 10)\n",
    "cross_validate(MultinomialNB(), features_train_tfidf_ubg, labels_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "Third, a grid search is performed in order to establish the best model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "calibrated_clf = CalibratedClassifierCV(base_estimator=clf, method='sigmoid', cv=10)  \n",
    "\n",
    "grid_params = {'base_estimator__alpha': [0.0001, 0.001, 0.01, 0.1]}  \n",
    "grid_search = GridSearchCV(estimator=calibrated_clf, param_grid=grid_params, cv=10)\n",
    "grid_search.fit(features_train_tfidf_ubg, labels_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.29      0.36        42\n",
      "           1       0.59      0.77      0.67        56\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.53      0.53      0.51        98\n",
      "weighted avg       0.54      0.56      0.53        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training and evaluating the classifier\n",
    "train_model(MultinomialNB(alpha = .01), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.71      0.62        42\n",
      "           1       0.72      0.55      0.63        56\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.63      0.63      0.62        98\n",
      "weighted avg       0.65      0.62      0.62        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(GaussianNB(), features_train_count, labels_train, features_test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best classifier for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(features_train_count, labels_train)\n",
    "nbc_final = clf.predict(features_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "First, the classifiers for different vectors are trained and evaluated on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.63        42\n",
      "           1       0.72      0.79      0.75        56\n",
      "\n",
      "    accuracy                           0.70        98\n",
      "   macro avg       0.70      0.69      0.69        98\n",
      "weighted avg       0.70      0.70      0.70        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.29      0.39        42\n",
      "           1       0.62      0.88      0.73        56\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.63      0.58      0.56        98\n",
      "weighted avg       0.63      0.62      0.58        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.26      0.39        42\n",
      "           1       0.63      0.95      0.76        56\n",
      "\n",
      "    accuracy                           0.65        98\n",
      "   macro avg       0.71      0.60      0.58        98\n",
      "weighted avg       0.70      0.65      0.60        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.40      0.47        42\n",
      "           1       0.63      0.77      0.69        56\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.60      0.59      0.58        98\n",
      "weighted avg       0.60      0.61      0.60        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(svm.SVC(), features_train_count, labels_train, features_test_count)\n",
    "train_model(svm.SVC(), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(svm.SVC(), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(svm.SVC(), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "Second, the results are cross-validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 (+/- 0.13)\n",
      "Accuracy: 0.78 (+/- 0.06)\n",
      "Accuracy: 0.72 (+/- 0.05)\n",
      "Accuracy: 0.78 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "cross_validate(svm.SVC(), features_train_count, labels_train, 10)\n",
    "cross_validate(svm.SVC(), features_train_tfidf_ug, labels_train, 10)\n",
    "cross_validate(svm.SVC(), features_train_tfidf_bg, labels_train, 10)\n",
    "cross_validate(svm.SVC(), features_train_tfidf_ubg, labels_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "Third, a grid search is performed in order to establish the best model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C\n",
    "C = [.0001, .001, .01]\n",
    "\n",
    "# gamma\n",
    "gamma = [.0001, .001, .01, .1, 1, 10, 100]\n",
    "\n",
    "# degree\n",
    "degree = [1, 2, 3, 4, 5]\n",
    "\n",
    "# kernel\n",
    "kernel = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# probability\n",
    "probability = [True]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'gamma': gamma,\n",
    "              'degree': degree,\n",
    "              'probability': probability\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "svc = svm.SVC()\n",
    "\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=svc,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='f1',\n",
    "                                   cv=10, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search for count vectors are:\n",
      "{'probability': True, 'kernel': 'linear', 'gamma': 0.0001, 'degree': 3, 'C': 0.01}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.7737994399068956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(features_train_count, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Random Search for count vectors are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search for tfidf vectors with unigrams are:\n",
      "{'probability': True, 'kernel': 'poly', 'gamma': 10, 'degree': 4, 'C': 0.01}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.7573195254232818\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(features_train_tfidf_ug, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Random Search for tfidf vectors with unigrams are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search for tfidf vectors with bigrams are:\n",
      "{'probability': True, 'kernel': 'poly', 'gamma': 0.001, 'degree': 4, 'C': 0.01}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.736950467124978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(features_train_tfidf_bg, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Random Search for tfidf vectors with bigrams are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "The best hyperparameters from Random Search for tfidf vectors with uni and bigrams are:\n",
      "{'probability': True, 'kernel': 'poly', 'gamma': 10, 'degree': 4, 'C': 0.01}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.7563813374183843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(features_train_tfidf_ubg, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Random Search for tfidf vectors with uni and bigrams are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.40      0.51        42\n",
      "           1       0.66      0.86      0.74        56\n",
      "\n",
      "    accuracy                           0.66        98\n",
      "   macro avg       0.67      0.63      0.63        98\n",
      "weighted avg       0.67      0.66      0.64        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(probability= True, kernel= \"linear\", gamma= 0.0001, degree= 3, C= 0.01, )\n",
    "\n",
    "#fit the model to the training data\n",
    "svc.fit(features_train_count, labels_train)\n",
    "\n",
    "#get predictions\n",
    "svc_pred = svc.predict(features_test_count)\n",
    "print(classification_report(labels_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.63        42\n",
      "           1       0.72      0.79      0.75        56\n",
      "\n",
      "    accuracy                           0.70        98\n",
      "   macro avg       0.70      0.69      0.69        98\n",
      "weighted avg       0.70      0.70      0.70        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = svm.SVC()\n",
    "base_model.fit(features_train_count, labels_train)\n",
    "\n",
    "svc_pred = base_model.predict(features_test_count)\n",
    "print(classification_report(labels_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best classification results for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_final = base_model.predict(features_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.17      0.27        42\n",
      "           1       0.60      0.95      0.74        56\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.65      0.56      0.50        98\n",
      "weighted avg       0.64      0.61      0.54        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.43      0.42        42\n",
      "           1       0.56      0.54      0.55        56\n",
      "\n",
      "    accuracy                           0.49        98\n",
      "   macro avg       0.48      0.48      0.48        98\n",
      "weighted avg       0.49      0.49      0.49        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.17      0.26        42\n",
      "           1       0.60      0.93      0.73        56\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.62      0.55      0.50        98\n",
      "weighted avg       0.61      0.60      0.53        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54        42\n",
      "           1       0.65      0.64      0.65        56\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.59      0.60      0.59        98\n",
      "weighted avg       0.60      0.60      0.60        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(KNeighborsClassifier(), features_train_count, labels_train, features_test_count)\n",
    "train_model(KNeighborsClassifier(), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(KNeighborsClassifier(), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(KNeighborsClassifier(), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "n_neighbors = [int(x) for x in np.linspace(start = 1, stop = 300, num = 200)]\n",
    "\n",
    "param_grid = {\"n_neighbors\": n_neighbors}\n",
    "\n",
    "# Create a base model\n",
    "knnc = KNeighborsClassifier()\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .2, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=knnc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring=\"f1\",\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Search for count vectors are:\n",
      "{'n_neighbors': 40}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.7450818224449899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    7.9s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(features_train_count, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Grid Search for count vectors are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "The best hyperparameters from Grid Search for tfidf vectors are:\n",
      "{'n_neighbors': 125}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.7786153150034552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(features_train_tfidf_ug, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Grid Search for tfidf vectors are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "The best hyperparameters from Grid Search for tfidf vectors with ngrams are:\n",
      "{'n_neighbors': 125}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.7275625697433444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    4.3s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(features_train_tfidf_bg, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Grid Search for tfidf vectors with ngrams are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "The best hyperparameters from Grid Search for tfidf vectors with ngrams are:\n",
      "{'n_neighbors': 134}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.7732016257181274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    8.2s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(features_train_tfidf_ubg, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Grid Search for tfidf vectors with ngrams are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=8, test_size=0.2, train_size=None),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [120, 121, 122, 123, 124, 125, 126, 127,\n",
       "                                         128, 129, 130]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130]\n",
    "param_grid = {'n_neighbors': n_neighbors}\n",
    "\n",
    "knnc = KNeighborsClassifier()\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .2, random_state = 8)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knnc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(features_train_tfidf_ug, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report - K nearest neighbour - 129 neighbours - tf idf vectors with unigrams\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.31      0.39        42\n",
      "           1       0.60      0.79      0.68        56\n",
      "\n",
      "    accuracy                           0.58        98\n",
      "   macro avg       0.56      0.55      0.54        98\n",
      "weighted avg       0.57      0.58      0.56        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate the best hyperparameters\n",
    "clf = KNeighborsClassifier(n_neighbors= 125)\n",
    "clf.fit(features_train_tfidf_ug, labels_train)\n",
    "print(\"classification report - K nearest neighbour - 129 neighbours - tf idf vectors with unigrams\") \n",
    "print(classification_report(labels_test, clf.predict(features_test_tfidf_ug)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54        42\n",
      "           1       0.65      0.64      0.65        56\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.59      0.60      0.59        98\n",
      "weighted avg       0.60      0.60      0.60        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = KNeighborsClassifier()\n",
    "base_model.fit(features_train_tfidf_ubg, labels_train)\n",
    "\n",
    "base_model_pred = base_model.predict(features_test_tfidf_ubg)\n",
    "print(classification_report(labels_test, base_model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best classification results for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_final = base_model_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report - Stochastic Gradiend Descent\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.52      0.51        42\n",
      "           1       0.63      0.61      0.62        56\n",
      "\n",
      "    accuracy                           0.57        98\n",
      "   macro avg       0.56      0.57      0.56        98\n",
      "weighted avg       0.57      0.57      0.57        98\n",
      "\n",
      "classification report - Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.71      0.62        42\n",
      "           1       0.72      0.55      0.63        56\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.63      0.63      0.62        98\n",
      "weighted avg       0.65      0.62      0.62        98\n",
      "\n",
      "classification report - SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.63        42\n",
      "           1       0.72      0.79      0.75        56\n",
      "\n",
      "    accuracy                           0.70        98\n",
      "   macro avg       0.70      0.69      0.69        98\n",
      "weighted avg       0.70      0.70      0.70        98\n",
      "\n",
      "classification report - k nearest neighbour\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54        42\n",
      "           1       0.65      0.64      0.65        56\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.59      0.60      0.59        98\n",
      "weighted avg       0.60      0.60      0.60        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report - Stochastic Gradiend Descent\") \n",
    "print(classification_report(labels_test, sgdc_final))\n",
    "print(\"classification report - Naive Bayes\") \n",
    "print(classification_report(labels_test, nbc_final))\n",
    "print(\"classification report - SVC\") \n",
    "print(classification_report(labels_test, svc_final))\n",
    "print(\"classification report - k nearest neighbour\") \n",
    "print(classification_report(labels_test, knn_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_neu.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(features_train_count, labels_train)\n",
    "joblib.dump(clf, 'classifier_neu.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.63        42\n",
      "           1       0.72      0.79      0.75        56\n",
      "\n",
      "    accuracy                           0.70        98\n",
      "   macro avg       0.70      0.69      0.69        98\n",
      "weighted avg       0.70      0.70      0.70        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_pred = clf.predict(features_test_count)\n",
    "print(classification_report(labels_test, svc_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
