{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning - Balance of actors classifier\n",
    "   \n",
    "In this notebook, the manual content analysis data is used to train and evaluate a classifier that assesses the balance of actors of an article.   \n",
    "The process includes feature selection, and the evaluation and comparison of different types of classifiers on different types of text representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from pprint import pprint\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the manually coded data\n",
    "df = read_excel(\"mca_cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove unreliable coders\n",
    "df = df[df.CID != 4]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    297\n",
       "1    152\n",
       "Name: BOA, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect the category distribution to see how balanced it is\n",
    "df[\"BOA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and testing dataset \n",
    "x_train, x_test, y_train, y_test = train_test_split(df[\"clean text\"], df.BOA, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "   \n",
    "Four different types of text representations for the classifier training were used, namely count vectors, TF-IDF vectors with unigrams, and TF-IDF vectors with bigrams and TF-IDF vectors with both uni- and bigrams. All classifiers were trained and tested on all features.   \n",
    "First, the labels, which remain in a binary format, are renamed. After that, the different vector types are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = y_train\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359, 200)\n",
      "(90, 200)\n"
     ]
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer=\"word\", \n",
    "                             token_pattern=r\"\\w{1,10}\", \n",
    "                             min_df = 10, \n",
    "                             max_df = 1., \n",
    "                             max_features=200)\n",
    "\n",
    "#features for training\n",
    "features_train_count = count_vect.fit_transform(x_train).toarray()\n",
    "\n",
    "#features for testing\n",
    "features_test_count = count_vect.fit_transform(x_test).toarray()\n",
    "\n",
    "#inspect the shape\n",
    "print(features_train_count.shape)\n",
    "print(features_test_count.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectors\n",
    "In the following, Term Frequency-Inverse Document Frequency is applied in order to represent the text data as a vector that can be used as numerical input for a SML algorithm. \n",
    "Three different vectors are created:\n",
    "    - A vector with unigrams only\n",
    "    - A vector with bigrams only\n",
    "    - A vector with unigrams & bigrams\n",
    "    \n",
    "In addition to that, several parameters were specified:\n",
    "    - Terms that appear in less than 10 documents are ignored -> min_df\n",
    "    - All other terms are included -> max_df\n",
    "    - In total, up to 200 features can be extracted per text -> max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359, 200)\n",
      "(90, 200)\n"
     ]
    }
   ],
   "source": [
    "# unigrams\n",
    "tfidf_vect_ug = TfidfVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}',\n",
    "                             ngram_range = (1,1),\n",
    "                             min_df = 10, \n",
    "                             max_df = 1., \n",
    "                             max_features=200)\n",
    "\n",
    "# bigrams\n",
    "tfidf_vect_bg = TfidfVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}',\n",
    "                             ngram_range = (2,2),\n",
    "                             min_df = 10, \n",
    "                             max_df = 1., \n",
    "                             max_features=5) #otherwise there is an error\n",
    "\n",
    "# unigrams and bigrams\n",
    "tfidf_vect_ubg = TfidfVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}',\n",
    "                             ngram_range = (1,2),\n",
    "                             min_df = 10, \n",
    "                             max_df = 1., \n",
    "                             max_features=200)\n",
    "\n",
    "\n",
    "#features for testing\n",
    "features_train_tfidf_ug = tfidf_vect_ug.fit_transform(x_train).toarray()\n",
    "features_train_tfidf_bg = tfidf_vect_bg.fit_transform(x_train).toarray()\n",
    "features_train_tfidf_ubg = tfidf_vect_ubg.fit_transform(x_train).toarray()\n",
    "\n",
    "#features (=y_train)\n",
    "features_test_tfidf_ug = tfidf_vect_ug.fit_transform(x_test).toarray()\n",
    "features_test_tfidf_bg = tfidf_vect_bg.fit_transform(x_test).toarray()\n",
    "features_test_tfidf_ubg = tfidf_vect_ubg.fit_transform(x_test).toarray()\n",
    "\n",
    "#Explore the shape of the features\n",
    "print(features_train_tfidf_ubg.shape)\n",
    "print(features_test_tfidf_ubg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training & evaluation\n",
    "In the following, different classifiers are trained and evaluated through their precision, recall and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, features_train, labels_train, features_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(features_train, labels_train)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(features_test)\n",
    "    #calculate the accuracy of the predictions\n",
    "    accuracy = classification_report(labels_test, predictions)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier\n",
    "First, the classifiers for different vectors are trained and evaluated on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.62        63\n",
      "           1       0.34      0.56      0.42        27\n",
      "\n",
      "    accuracy                           0.54        90\n",
      "   macro avg       0.54      0.55      0.52        90\n",
      "weighted avg       0.62      0.54      0.56        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        63\n",
      "           1       0.26      0.33      0.30        27\n",
      "\n",
      "    accuracy                           0.52        90\n",
      "   macro avg       0.47      0.47      0.47        90\n",
      "weighted avg       0.55      0.52      0.54        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.10      0.17        63\n",
      "           1       0.30      0.93      0.46        27\n",
      "\n",
      "    accuracy                           0.34        90\n",
      "   macro avg       0.53      0.51      0.31        90\n",
      "weighted avg       0.62      0.34      0.26        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.67        63\n",
      "           1       0.27      0.30      0.28        27\n",
      "\n",
      "    accuracy                           0.54        90\n",
      "   macro avg       0.47      0.47      0.47        90\n",
      "weighted avg       0.56      0.54      0.55        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining the classifier\n",
    "sgdc = SGDClassifier(loss=\"hinge\", max_iter=200, random_state=8) \n",
    "#training and evaluating the classifier\n",
    "train_model(sgdc, features_train_count, labels_train, features_test_count)\n",
    "train_model(sgdc, features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(sgdc, features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(sgdc, features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning & cross validation\n",
    "Second, a grid search is performed in order to establish and cross-validate the best model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectors: {'base_estimator__alpha': 0.1}\n",
      "Accuracy: 0.46 (+/- 0.18)\n",
      "None\n",
      "TF-IDF vectors with unigrams: {'base_estimator__alpha': 0.01}\n",
      "Accuracy: 0.46 (+/- 0.15)\n",
      "None\n",
      "TF-IDF vectors with bigrams: {'base_estimator__alpha': 0.1}\n",
      "Accuracy: 0.46 (+/- 0.15)\n",
      "None\n",
      "TF-IDF vectors with uni- and bigrams: {'base_estimator__alpha': 0.1}\n",
      "Accuracy: 0.44 (+/- 0.10)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def cross_validate(classifier, features_train, labels_train, cv):\n",
    "    scores = cross_val_score(classifier, features_train, labels_train, cv=cv, scoring =\"f1\")\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "clf = SGDClassifier(loss=\"hinge\", max_iter=200, random_state=8)\n",
    "calibrated_clf = CalibratedClassifierCV(base_estimator=clf, method=\"sigmoid\", cv=10)  \n",
    "grid_params = {\"base_estimator__alpha\": [0.0001, 0.001, 0.01, 0.1]}  \n",
    "grid_search = GridSearchCV(estimator=calibrated_clf, param_grid=grid_params, cv=10)\n",
    "grid_search.fit(features_train_tfidf_bg, labels_train)\n",
    "print(\"Count vectors:\", grid_search.best_params_)\n",
    "print(cross_validate(sgdc, features_train_count, labels_train, 10))\n",
    "grid_search.fit(features_train_count, labels_train)\n",
    "print(\"TF-IDF vectors with unigrams:\", grid_search.best_params_)\n",
    "print(cross_validate(sgdc, features_train_tfidf_ug, labels_train, 10))\n",
    "grid_search.fit(features_train_tfidf_ug, labels_train)\n",
    "print(\"TF-IDF vectors with bigrams:\", grid_search.best_params_)\n",
    "print(cross_validate(sgdc, features_train_tfidf_ug, labels_train, 10))\n",
    "grid_search.fit(features_train_tfidf_bg, labels_train)\n",
    "print(\"TF-IDF vectors with uni- and bigrams:\",grid_search.best_params_)\n",
    "print(cross_validate(sgdc, features_train_tfidf_ubg, labels_train, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68        63\n",
      "           1       0.31      0.37      0.34        27\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.51      0.51      0.51        90\n",
      "weighted avg       0.59      0.57      0.58        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.35      0.50      0.41        90\n",
      "weighted avg       0.49      0.70      0.58        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.35      0.50      0.41        90\n",
      "weighted avg       0.49      0.70      0.58        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.35      0.50      0.41        90\n",
      "weighted avg       0.49      0.70      0.58        90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#incorporating the grid-search results for training and evaluating the classifiers for different vectors\n",
    "train_model(SGDClassifier(loss=\"hinge\", alpha = .1, max_iter=200, random_state=8), features_train_count, labels_train, features_test_count)\n",
    "train_model(SGDClassifier(loss=\"hinge\", alpha = .01, max_iter=200, random_state=8), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(SGDClassifier(loss=\"hinge\", alpha = .1, max_iter=200, random_state=8), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(SGDClassifier(loss=\"hinge\", alpha = .1, max_iter=200, random_state=8), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best classification results for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss=\"hinge\", alpha = .1, max_iter=200, random_state=8)\n",
    "clf.fit(features_train_count, labels_train)\n",
    "sgdc_final = clf.predict(features_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "First, the classifiers for different vectors are trained and evaluated on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.52      0.61        63\n",
      "           1       0.32      0.52      0.39        27\n",
      "\n",
      "    accuracy                           0.52        90\n",
      "   macro avg       0.52      0.52      0.50        90\n",
      "weighted avg       0.60      0.52      0.54        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.71        63\n",
      "           1       0.29      0.26      0.27        27\n",
      "\n",
      "    accuracy                           0.59        90\n",
      "   macro avg       0.49      0.49      0.49        90\n",
      "weighted avg       0.58      0.59      0.58        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81        63\n",
      "           1       0.44      0.15      0.22        27\n",
      "\n",
      "    accuracy                           0.69        90\n",
      "   macro avg       0.58      0.53      0.51        90\n",
      "weighted avg       0.63      0.69      0.63        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76        63\n",
      "           1       0.42      0.37      0.39        27\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.58      0.57      0.58        90\n",
      "weighted avg       0.64      0.66      0.65        90\n",
      "\n",
      "\n",
      "\n",
      "Multinomial NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.30      0.40        63\n",
      "           1       0.25      0.56      0.35        27\n",
      "\n",
      "    accuracy                           0.38        90\n",
      "   macro avg       0.43      0.43      0.38        90\n",
      "weighted avg       0.51      0.38      0.39        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        63\n",
      "           1       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.71        90\n",
      "   macro avg       0.85      0.52      0.45        90\n",
      "weighted avg       0.80      0.71      0.60        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.69        90\n",
      "   macro avg       0.35      0.49      0.41        90\n",
      "weighted avg       0.49      0.69      0.57        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.35      0.50      0.41        90\n",
      "weighted avg       0.49      0.70      0.58        90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "print(\"Gaussian NB\")\n",
    "train_model(GaussianNB(), features_train_count, labels_train, features_test_count)\n",
    "train_model(GaussianNB(), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(GaussianNB(), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(GaussianNB(), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Multinomial NB\")\n",
    "train_model(MultinomialNB(), features_train_count, labels_train, features_test_count)\n",
    "train_model(MultinomialNB(), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(MultinomialNB(), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(MultinomialNB(), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "Second, a grid search is performed in order to establish and cross-validate the best model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectors: {'base_estimator__alpha': 0.0001}\n",
      "Accuracy: 0.46 (+/- 0.18)\n",
      "None\n",
      "TF-IDF vectors with unigrams: {'base_estimator__alpha': 0.0001}\n",
      "Accuracy: 0.46 (+/- 0.15)\n",
      "None\n",
      "TF-IDF vectors with bigrams: {'base_estimator__alpha': 0.1}\n",
      "Accuracy: 0.46 (+/- 0.15)\n",
      "None\n",
      "TF-IDF vectors with uni- and bigrams: {'base_estimator__alpha': 0.0001}\n",
      "Accuracy: 0.44 (+/- 0.10)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "calibrated_clf = CalibratedClassifierCV(base_estimator=clf, method=\"sigmoid\", cv=10)  \n",
    "grid_params = {\"base_estimator__alpha\": [0.0001, 0.001, 0.01, 0.1]}  \n",
    "grid_search = GridSearchCV(estimator=calibrated_clf, param_grid=grid_params, cv=10)\n",
    "grid_search.fit(features_train_tfidf_bg, labels_train)\n",
    "print(\"Count vectors:\", grid_search.best_params_)\n",
    "print(cross_validate(sgdc, features_train_count, labels_train, 10))\n",
    "grid_search.fit(features_train_count, labels_train)\n",
    "print(\"TF-IDF vectors with unigrams:\", grid_search.best_params_)\n",
    "print(cross_validate(sgdc, features_train_tfidf_ug, labels_train, 10))\n",
    "grid_search.fit(features_train_tfidf_ug, labels_train)\n",
    "print(\"TF-IDF vectors with bigrams:\", grid_search.best_params_)\n",
    "print(cross_validate(sgdc, features_train_tfidf_ug, labels_train, 10))\n",
    "grid_search.fit(features_train_tfidf_bg, labels_train)\n",
    "print(\"TF-IDF vectors with uni- and bigrams:\",grid_search.best_params_)\n",
    "print(cross_validate(sgdc, features_train_tfidf_ubg, labels_train, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.32      0.42        63\n",
      "           1       0.26      0.56      0.35        27\n",
      "\n",
      "    accuracy                           0.39        90\n",
      "   macro avg       0.44      0.44      0.39        90\n",
      "weighted avg       0.52      0.39      0.40        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        63\n",
      "           1       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.71        90\n",
      "   macro avg       0.85      0.52      0.45        90\n",
      "weighted avg       0.80      0.71      0.60        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.69        90\n",
      "   macro avg       0.35      0.49      0.41        90\n",
      "weighted avg       0.49      0.69      0.57        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.35      0.50      0.41        90\n",
      "weighted avg       0.49      0.70      0.58        90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#incorporating the grid-search results for training and evaluating the classifiers for different vectors\n",
    "train_model(MultinomialNB(alpha = .0001), features_train_count, labels_train, features_test_count)\n",
    "train_model(MultinomialNB(alpha = .0001), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(MultinomialNB(alpha = .1,), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(MultinomialNB(alpha = .0001), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76        63\n",
      "           1       0.42      0.37      0.39        27\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.58      0.57      0.58        90\n",
      "weighted avg       0.64      0.66      0.65        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compare results with the best Gaussian classifier\n",
    "train_model(GaussianNB(), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best classifier for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(features_train_tfidf_ubg, labels_train)\n",
    "nbc_final = clf.predict(features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "First, the classifiers for different vectors are trained and evaluated on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82        63\n",
      "           1       0.57      0.15      0.24        27\n",
      "\n",
      "    accuracy                           0.71        90\n",
      "   macro avg       0.65      0.55      0.53        90\n",
      "weighted avg       0.68      0.71      0.65        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.83        63\n",
      "           1       1.00      0.07      0.14        27\n",
      "\n",
      "    accuracy                           0.72        90\n",
      "   macro avg       0.86      0.54      0.49        90\n",
      "weighted avg       0.80      0.72      0.63        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80        63\n",
      "           1       0.33      0.07      0.12        27\n",
      "\n",
      "    accuracy                           0.68        90\n",
      "   macro avg       0.52      0.51      0.46        90\n",
      "weighted avg       0.59      0.68      0.60        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.35      0.50      0.41        90\n",
      "weighted avg       0.49      0.70      0.58        90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_model(svm.SVC(random_state=8), features_train_count, labels_train, features_test_count)\n",
    "train_model(svm.SVC(random_state=8), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(svm.SVC(random_state=8), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(svm.SVC(random_state=8), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "Second, a grid search is performed in order to establish and cross-validate the best model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C\n",
    "C = [.0001, .001, .01]\n",
    "\n",
    "# gamma\n",
    "gamma = [.0001, .001, .01, .1, 1, 10, 100]\n",
    "\n",
    "# degree\n",
    "degree = [1, 2, 3, 4, 5]\n",
    "\n",
    "# kernel\n",
    "kernel = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# probability\n",
    "probability = [True]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'gamma': gamma,\n",
    "              'degree': degree,\n",
    "              'probability': probability\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "svc = svm.SVC(random_state=8)\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=svc,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='f1',\n",
    "                                   cv=10, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search for count vectors are:\n",
      "{'probability': True, 'kernel': 'poly', 'gamma': 10, 'degree': 4, 'C': 0.01}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.5101051972418034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(features_train_count, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Random Search for count vectors are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search for tfidf vectors with unigrams are:\n",
      "{'probability': True, 'kernel': 'poly', 'gamma': 10, 'degree': 4, 'C': 0.01}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.1534938590820944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(features_train_tfidf_ug, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Random Search for tfidf vectors with unigrams are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search for tfidf vectors with bigrams are:\n",
      "{'probability': True, 'kernel': 'poly', 'gamma': 100, 'degree': 4, 'C': 0.01}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.1742150247413405\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(features_train_tfidf_bg, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Random Search for tfidf vectors with bigrams are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search for tfidf vectors with uni and bigrams are:\n",
      "{'probability': True, 'kernel': 'poly', 'gamma': 10, 'degree': 4, 'C': 0.01}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.1534938590820944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(features_train_tfidf_ubg, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Random Search for tfidf vectors with uni and bigrams are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76        63\n",
      "           1       0.42      0.37      0.39        27\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.58      0.57      0.58        90\n",
      "weighted avg       0.64      0.66      0.65        90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.35      0.50      0.41        90\n",
      "weighted avg       0.49      0.70      0.58        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.79        63\n",
      "           1       0.29      0.07      0.12        27\n",
      "\n",
      "    accuracy                           0.67        90\n",
      "   macro avg       0.49      0.50      0.46        90\n",
      "weighted avg       0.57      0.67      0.59        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        63\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.35      0.50      0.41        90\n",
      "weighted avg       0.49      0.70      0.58        90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#incorporate grid_search results\n",
    "train_model(svm.SVC(random_state=8, probability= True, kernel= 'poly', gamma= 10, degree= 4, C= 0.01), features_train_count, labels_train, features_test_count)\n",
    "train_model(svm.SVC(random_state=8, probability= True, kernel= 'poly', gamma= 10, degree= 4, C= 0.01), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(svm.SVC(random_state=8, probability= True, kernel= 'poly', gamma= 100, degree= 4, C= 0.01), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(svm.SVC(random_state=8, probability= True, kernel= 'poly', gamma= 10, degree= 4, C= 0.01), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82        63\n",
      "           1       0.57      0.15      0.24        27\n",
      "\n",
      "    accuracy                           0.71        90\n",
      "   macro avg       0.65      0.55      0.53        90\n",
      "weighted avg       0.68      0.71      0.65        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compare it to the base model for the vectors that achieved the best results\n",
    "base_model = svm.SVC()\n",
    "base_model.fit(features_train_count, labels_train)\n",
    "\n",
    "svc_pred = base_model.predict(features_test_count)\n",
    "print(classification_report(labels_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best classification results for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(random_state=8, probability= True, kernel= 'poly', gamma= 10, degree= 4, C= 0.01)\n",
    "clf.fit(features_train_count, labels_train)\n",
    "svc_final = clf.predict(features_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81        63\n",
      "           1       0.44      0.15      0.22        27\n",
      "\n",
      "    accuracy                           0.69        90\n",
      "   macro avg       0.58      0.53      0.51        90\n",
      "weighted avg       0.63      0.69      0.63        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        63\n",
      "           1       0.32      0.41      0.36        27\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.52      0.52      0.52        90\n",
      "weighted avg       0.60      0.57      0.58        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.81        63\n",
      "           1       0.40      0.07      0.12        27\n",
      "\n",
      "    accuracy                           0.69        90\n",
      "   macro avg       0.55      0.51      0.47        90\n",
      "weighted avg       0.61      0.69      0.61        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        63\n",
      "           1       0.32      0.41      0.36        27\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.52      0.52      0.52        90\n",
      "weighted avg       0.60      0.57      0.58        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(KNeighborsClassifier(), features_train_count, labels_train, features_test_count)\n",
    "train_model(KNeighborsClassifier(), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(KNeighborsClassifier(), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(KNeighborsClassifier(), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "n_neighbors = [int(x) for x in np.linspace(start = 1, stop = 250, num = 200)]\n",
    "\n",
    "param_grid = {\"n_neighbors\": n_neighbors}\n",
    "\n",
    "# Create a base model\n",
    "knnc = KNeighborsClassifier()\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .2, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=knnc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring=\"f1\",\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Search for count vectors are:\n",
      "{'n_neighbors': 3}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.43412698412698414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    8.0s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(features_train_count, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Grid Search for count vectors are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "The best hyperparameters from Grid Search for tfidf vectors are:\n",
      "{'n_neighbors': 7}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.4282682770077728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(features_train_tfidf_ug, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Grid Search for tfidf vectors are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "The best hyperparameters from Grid Search for tfidf vectors with ngrams are:\n",
      "{'n_neighbors': 1}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.39477124183006534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(features_train_tfidf_bg, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Grid Search for tfidf vectors with ngrams are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "The best hyperparameters from Grid Search for tfidf vectors with ngrams are:\n",
      "{'n_neighbors': 7}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.4272249060654858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(features_train_tfidf_ubg, labels_train)\n",
    "\n",
    "print(\"The best hyperparameters from Grid Search for tfidf vectors with ngrams are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.81        63\n",
      "           1       0.50      0.15      0.23        27\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.61      0.54      0.52        90\n",
      "weighted avg       0.65      0.70      0.64        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        63\n",
      "           1       0.35      0.30      0.32        27\n",
      "\n",
      "    accuracy                           0.62        90\n",
      "   macro avg       0.53      0.53      0.53        90\n",
      "weighted avg       0.61      0.62      0.61        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.37      0.47        63\n",
      "           1       0.27      0.56      0.37        27\n",
      "\n",
      "    accuracy                           0.42        90\n",
      "   macro avg       0.46      0.46      0.42        90\n",
      "weighted avg       0.54      0.42      0.44        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67        63\n",
      "           1       0.30      0.37      0.33        27\n",
      "\n",
      "    accuracy                           0.56        90\n",
      "   macro avg       0.50      0.50      0.50        90\n",
      "weighted avg       0.58      0.56      0.57        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#incorporating the grid-search results for training and evaluating the classifiers for different vectors\n",
    "train_model(KNeighborsClassifier(n_neighbors= 3), features_train_count, labels_train, features_test_count)\n",
    "train_model(KNeighborsClassifier(n_neighbors= 7), features_train_tfidf_ug, labels_train, features_test_tfidf_ug)\n",
    "train_model(KNeighborsClassifier(n_neighbors= 1), features_train_tfidf_bg, labels_train, features_test_tfidf_bg)\n",
    "train_model(KNeighborsClassifier(n_neighbors= 7), features_train_tfidf_ubg, labels_train, features_test_tfidf_ubg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        63\n",
      "           1       0.32      0.41      0.36        27\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.52      0.52      0.52        90\n",
      "weighted avg       0.60      0.57      0.58        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compare results to the best base model\n",
    "base_model = KNeighborsClassifier()\n",
    "base_model.fit(features_train_tfidf_ubg, labels_train)\n",
    "\n",
    "base_model_pred = base_model.predict(features_test_tfidf_ubg)\n",
    "print(classification_report(labels_test, base_model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best classification results for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors= 7)\n",
    "clf.fit(features_train_tfidf_ug, labels_train)\n",
    "knn_final = clf.predict(features_test_tfidf_ug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report - Stochastic Gradiend Descent\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68        63\n",
      "           1       0.31      0.37      0.34        27\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.51      0.51      0.51        90\n",
      "weighted avg       0.59      0.57      0.58        90\n",
      "\n",
      "classification report - Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76        63\n",
      "           1       0.42      0.37      0.39        27\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.58      0.57      0.58        90\n",
      "weighted avg       0.64      0.66      0.65        90\n",
      "\n",
      "classification report - SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76        63\n",
      "           1       0.42      0.37      0.39        27\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.58      0.57      0.58        90\n",
      "weighted avg       0.64      0.66      0.65        90\n",
      "\n",
      "classification report - k nearest neighbour\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        63\n",
      "           1       0.35      0.30      0.32        27\n",
      "\n",
      "    accuracy                           0.62        90\n",
      "   macro avg       0.53      0.53      0.53        90\n",
      "weighted avg       0.61      0.62      0.61        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report - Stochastic Gradiend Descent\") \n",
    "print(classification_report(labels_test, sgdc_final))\n",
    "print(\"classification report - Naive Bayes\") \n",
    "print(classification_report(labels_test, nbc_final))\n",
    "print(\"classification report - SVC\") \n",
    "print(classification_report(labels_test, svc_final))\n",
    "print(\"classification report - k nearest neighbour\") \n",
    "print(classification_report(labels_test, knn_final))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
